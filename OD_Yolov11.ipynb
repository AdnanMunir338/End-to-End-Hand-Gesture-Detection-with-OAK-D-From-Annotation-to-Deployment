{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics\n",
        "\n",
        "from IPython import display\n",
        "display.clear_output()\n",
        "!yolo mode=checks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-p9MIF-awC4T",
        "outputId": "a602a0cb-746a-4b8e-f09f-db7a8dd61d95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file âœ… \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/yolo\", line 8, in <module>\n",
            "    sys.exit(entrypoint())\n",
            "             ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ultralytics/cfg/__init__.py\", line 920, in entrypoint\n",
            "    raise ValueError(f\"Invalid 'mode={mode}'. Valid modes are {MODES}.\\n{CLI_HELP_MSG}\")\n",
            "ValueError: Invalid 'mode=<module 'ultralytics.utils.checks' from '/usr/local/lib/python3.11/dist-packages/ultralytics/utils/checks.py'>'. Valid modes are frozenset({'benchmark', 'train', 'val', 'track', 'predict', 'export'}).\n",
            "\n",
            "    Arguments received: ['yolo', 'mode=checks']. Ultralytics 'yolo' commands use the following syntax:\n",
            "\n",
            "        yolo TASK MODE ARGS\n",
            "\n",
            "        Where   TASK (optional) is one of frozenset({'classify', 'segment', 'obb', 'detect', 'pose'})\n",
            "                MODE (required) is one of frozenset({'benchmark', 'train', 'val', 'track', 'predict', 'export'})\n",
            "                ARGS (optional) are any number of custom 'arg=value' pairs like 'imgsz=320' that override defaults.\n",
            "                    See all ARGS at https://docs.ultralytics.com/usage/cfg or with 'yolo cfg'\n",
            "\n",
            "    1. Train a detection model for 10 epochs with an initial learning_rate of 0.01\n",
            "        yolo train data=coco8.yaml model=yolo11n.pt epochs=10 lr0=0.01\n",
            "\n",
            "    2. Predict a YouTube video using a pretrained segmentation model at image size 320:\n",
            "        yolo predict model=yolo11n-seg.pt source='https://youtu.be/LNwODJXcvt4' imgsz=320\n",
            "\n",
            "    3. Val a pretrained detection model at batch-size 1 and image size 640:\n",
            "        yolo val model=yolo11n.pt data=coco8.yaml batch=1 imgsz=640\n",
            "\n",
            "    4. Export a YOLO11n classification model to ONNX format at image size 224 by 128 (no TASK required)\n",
            "        yolo export model=yolo11n-cls.pt format=onnx imgsz=224,128\n",
            "\n",
            "    5. Ultralytics solutions usage\n",
            "        yolo solutions count or in ['crop', 'blur', 'workout', 'heatmap', 'isegment', 'visioneye', 'speed', 'queue', 'analytics', 'inference', 'trackzone'] source=\"path/to/video/file.mp4\"\n",
            "\n",
            "    6. Run special commands:\n",
            "        yolo help\n",
            "        yolo checks\n",
            "        yolo version\n",
            "        yolo settings\n",
            "        yolo copy-cfg\n",
            "        yolo cfg\n",
            "        yolo solutions help\n",
            "\n",
            "    Docs: https://docs.ultralytics.com\n",
            "    Solutions: https://docs.ultralytics.com/solutions/\n",
            "    Community: https://community.ultralytics.com\n",
            "    GitHub: https://github.com/ultralytics/ultralytics\n",
            "    \n",
            "Sentry is attempting to send 2 pending events\n",
            "Waiting up to 2 seconds\n",
            "Press Ctrl-C to quit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"FIUDhCS3sMERblQJ1B79\")\n",
        "project = rf.workspace(\"lebanese-university-grkoz\").project(\"hand-gesture-recognition-y5827\")\n",
        "version = project.version(6)\n",
        "dataset = version.download(\"yolov8\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nj646ljZ5MfD",
        "outputId": "dea022c8-e5f2-4f53-8157-04dcc6f8abfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting roboflow\n",
            "  Downloading roboflow-1.1.58-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from roboflow) (2025.1.31)\n",
            "Collecting idna==3.7 (from roboflow)\n",
            "  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.11/dist-packages (from roboflow) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.4.8)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from roboflow) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.0.2)\n",
            "Collecting opencv-python-headless==4.10.0.84 (from roboflow)\n",
            "  Downloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from roboflow) (11.1.0)\n",
            "Collecting pillow-heif>=0.18.0 (from roboflow)\n",
            "  Downloading pillow_heif-0.22.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.8.2)\n",
            "Collecting python-dotenv (from roboflow)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.32.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.17.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.3.0)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from roboflow) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from roboflow) (6.0.2)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.0.0)\n",
            "Collecting filetype (from roboflow)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (1.3.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (4.56.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (3.2.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->roboflow) (3.4.1)\n",
            "Downloading roboflow-1.1.58-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m84.5/84.5 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.7-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow_heif-0.22.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: filetype, python-dotenv, pillow-heif, opencv-python-headless, idna, roboflow\n",
            "  Attempting uninstall: opencv-python-headless\n",
            "    Found existing installation: opencv-python-headless 4.11.0.86\n",
            "    Uninstalling opencv-python-headless-4.11.0.86:\n",
            "      Successfully uninstalled opencv-python-headless-4.11.0.86\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "Successfully installed filetype-1.2.0 idna-3.7 opencv-python-headless-4.10.0.84 pillow-heif-0.22.0 python-dotenv-1.0.1 roboflow-1.1.58\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in Hand-Gesture-Recognition-6 to yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6811/6811 [00:00<00:00, 16484.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to Hand-Gesture-Recognition-6 in yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1690/1690 [00:00<00:00, 6464.64it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YgDfg0_Vr9v3",
        "outputId": "97d5b541-602e-413f-fd72-2dceafa1dc10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.92 ğŸš€ Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=/content/yolo11n.pt, data=/content/Hand-Gesture-Recognition-6/data.yaml, epochs=60, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=yolov8_custom4, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/yolov8_custom4\n",
            "Overriding model.yaml nc=80 with nc=5\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
            "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
            " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
            " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
            " 23        [16, 19, 22]  1    431647  ultralytics.nn.modules.head.Detect           [5, [64, 128, 256]]           \n",
            "YOLO11n summary: 181 layers, 2,590,815 parameters, 2,590,799 gradients, 6.4 GFLOPs\n",
            "\n",
            "Transferred 448/499 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/yolov8_custom4', view at http://localhost:6006/\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/Hand-Gesture-Recognition-6/train/labels.cache... 587 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 587/587 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/Hand-Gesture-Recognition-6/valid/labels.cache... 167 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 167/167 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/detect/yolov8_custom4/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001111, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/yolov8_custom4\u001b[0m\n",
            "Starting training for 60 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/60      2.39G      1.252      3.514      1.684         15        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:13<00:00,  2.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        167        167    0.00938      0.989      0.202     0.0981\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/60      2.55G      1.198      2.897      1.576         24        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:11<00:00,  3.27it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        167        167       0.15     0.0678      0.164     0.0799\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/60      2.55G        1.2      2.557       1.57         30        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:11<00:00,  3.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        167        167      0.228      0.476      0.264      0.162\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/60      2.55G      1.315      2.468      1.629         19        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:10<00:00,  3.40it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        167        167      0.204      0.486       0.28      0.151\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/60      2.55G      1.284      2.363      1.589         23        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:10<00:00,  3.48it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        167        167      0.278      0.437      0.351      0.217\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/60      2.55G      1.264      2.205       1.57         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:10<00:00,  3.63it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  3.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        167        167      0.186      0.657      0.333       0.18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/60      2.55G      1.269      2.194      1.594         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:09<00:00,  3.96it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  3.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        167        167      0.293      0.415      0.287      0.169\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/60      2.55G      1.202      2.053      1.518         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:09<00:00,  3.96it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        167        167      0.319      0.595      0.393      0.241\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/60      2.55G      1.219      1.995      1.559         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:10<00:00,  3.61it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        167        167      0.321       0.61      0.468      0.308\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/60      2.55G       1.19      1.949      1.527         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:12<00:00,  3.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        167        167      0.435      0.517      0.438      0.278\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      11/60      2.55G      1.156      1.884      1.495         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:10<00:00,  3.43it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        167        167      0.494      0.595      0.536      0.365\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      12/60      2.56G      1.184      1.811      1.497         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:10<00:00,  3.46it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        167        167      0.447      0.647        0.5      0.325\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      13/60      2.56G       1.15      1.751      1.475         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:10<00:00,  3.54it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        167        167      0.485      0.563       0.51      0.347\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      14/60      2.58G      1.155       1.74      1.505         25        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:10<00:00,  3.54it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  3.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        167        167      0.551       0.65       0.63      0.441\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      15/60      2.59G      1.117      1.635      1.471         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:09<00:00,  3.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  3.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        167        167      0.476      0.628      0.616      0.449\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      16/60      2.59G      1.137      1.598      1.459         23        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:09<00:00,  3.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        167        167      0.546      0.598       0.64       0.47\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      17/60      2.59G      1.132      1.603      1.457         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:10<00:00,  3.62it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        167        167      0.578      0.673      0.644      0.456\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      18/60      2.59G      1.071      1.565      1.414         27        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:10<00:00,  3.47it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        167        167      0.556      0.602      0.619      0.438\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      19/60      2.59G      1.073      1.513      1.425         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:10<00:00,  3.45it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  5.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        167        167      0.538      0.722      0.673      0.495\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      20/60      2.59G      1.108      1.526       1.45         24        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:10<00:00,  3.48it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        167        167       0.54      0.619      0.592      0.414\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      21/60      2.59G      1.071      1.455       1.41         27        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:10<00:00,  3.57it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  3.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        167        167      0.419      0.719      0.561       0.42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      22/60      2.59G      1.058      1.463      1.412         27        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:09<00:00,  3.93it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:02<00:00,  2.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        167        167      0.444      0.754      0.616      0.456\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      23/60      2.59G      1.048      1.453      1.404         24        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:09<00:00,  4.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        167        167       0.67      0.612      0.691      0.499\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      24/60      2.59G      1.027      1.409      1.384         28        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:10<00:00,  3.55it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  5.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        167        167      0.553      0.718      0.678      0.498\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      25/60      2.59G      1.037      1.411      1.395         28        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:10<00:00,  3.53it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        167        167      0.595      0.619      0.674      0.512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      26/60      2.59G     0.9982      1.365      1.363         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:10<00:00,  3.54it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        167        167      0.706      0.603       0.75      0.555\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      27/60      2.59G      1.022      1.331       1.37         24        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:10<00:00,  3.47it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  5.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        167        167      0.583      0.748      0.743      0.561\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      28/60      2.59G     0.9765        1.3      1.334         24        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:10<00:00,  3.44it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        167        167      0.772      0.675      0.774       0.58\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      29/60      2.59G     0.9775      1.256      1.362         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:09<00:00,  3.83it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  3.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        167        167       0.66      0.715      0.754      0.574\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      30/60      2.59G     0.9941      1.296      1.366         28        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:08<00:00,  4.12it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  3.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        167        167        0.7      0.725      0.773      0.586\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      31/60      2.59G      1.024       1.29      1.365         25        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:10<00:00,  3.69it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  5.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        167        167       0.72      0.735      0.757      0.575\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      32/60      2.59G     0.9236      1.253       1.32         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:10<00:00,  3.45it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        167        167      0.691      0.716      0.765      0.578\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      33/60      2.59G     0.9923       1.26      1.339         27        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:10<00:00,  3.48it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  5.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        167        167      0.698      0.705      0.767      0.584\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      34/60      2.59G     0.9689      1.236      1.333         23        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:10<00:00,  3.50it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        167        167      0.635      0.735      0.745      0.568\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      35/60      2.59G     0.9746      1.236      1.338         30        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:10<00:00,  3.43it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        167        167      0.564      0.746      0.704      0.536\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      36/60      2.59G     0.9784      1.181      1.356         30        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:10<00:00,  3.63it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  3.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        167        167      0.644      0.728      0.758      0.549\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      37/60      2.59G     0.9314      1.163      1.327         19        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:09<00:00,  4.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  3.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        167        167      0.676       0.72      0.759      0.608\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      38/60      2.59G     0.9805      1.196      1.352         28        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:09<00:00,  3.77it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        167        167      0.751      0.728        0.8      0.617\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      39/60      2.59G     0.9118      1.119      1.313         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:10<00:00,  3.40it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        167        167       0.67      0.801      0.781      0.608\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      40/60      2.59G     0.9167      1.134      1.296         28        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:10<00:00,  3.39it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  5.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        167        167      0.688      0.734      0.764      0.581\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      41/60      2.59G     0.9302      1.104      1.307         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:10<00:00,  3.46it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        167        167        0.7      0.715      0.788      0.591\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      42/60      2.59G     0.9206      1.137      1.307         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:10<00:00,  3.46it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        167        167      0.711      0.711      0.781      0.599\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      43/60      2.59G     0.9085      1.076        1.3         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:10<00:00,  3.49it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        167        167      0.742      0.744      0.782      0.608\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      44/60      2.59G     0.8852      1.084      1.298         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:09<00:00,  3.86it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  3.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        167        167      0.716      0.747      0.803      0.601\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      45/60      2.59G      0.882      1.072      1.271         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:09<00:00,  4.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        167        167      0.758      0.753        0.8      0.617\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      46/60      2.59G     0.8746       1.07      1.278         27        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:10<00:00,  3.64it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        167        167      0.842      0.736      0.842      0.661\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      47/60      2.59G     0.8586      1.063      1.258         20        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:10<00:00,  3.48it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        167        167      0.701       0.77      0.796      0.632\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      48/60      2.59G     0.8449      1.005      1.249         32        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:10<00:00,  3.43it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        167        167      0.737      0.726      0.786       0.62\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      49/60      2.59G     0.8538      1.047      1.255         24        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:10<00:00,  3.46it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        167        167      0.714      0.812      0.818      0.649\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      50/60      2.59G     0.8671     0.9991      1.278         26        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:10<00:00,  3.46it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        167        167      0.689      0.795      0.808       0.65\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      51/60      2.59G     0.6643     0.6685      1.199         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:11<00:00,  3.12it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        167        167      0.761      0.748      0.804      0.635\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      52/60      2.59G     0.6626     0.6221      1.209         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:09<00:00,  3.88it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  3.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        167        167      0.784      0.725      0.791      0.622\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      53/60      2.59G     0.6431     0.5988      1.227         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:08<00:00,  4.23it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        167        167      0.736      0.781      0.822       0.66\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      54/60      2.59G     0.6292      0.571      1.191         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:09<00:00,  3.73it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  5.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        167        167      0.799      0.797      0.843      0.675\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      55/60      2.59G     0.6261     0.5518      1.188         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:10<00:00,  3.56it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  5.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        167        167      0.782       0.75      0.817      0.649\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      56/60      2.59G     0.6065     0.5218      1.142         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:10<00:00,  3.57it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        167        167      0.784      0.747      0.827      0.649\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      57/60      2.59G     0.6117     0.5132      1.178         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:10<00:00,  3.64it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  4.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        167        167      0.797      0.758      0.837      0.665\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      58/60      2.59G     0.5904     0.5002      1.158         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:10<00:00,  3.69it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  3.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        167        167       0.79      0.766      0.827      0.658\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      59/60      2.59G     0.5771     0.4949      1.137         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:08<00:00,  4.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  3.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        167        167      0.806      0.739      0.827      0.656\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      60/60      2.59G     0.5698     0.4791      1.149         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 37/37 [00:09<00:00,  3.87it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  5.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        167        167        0.8      0.755      0.826      0.658\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "60 epochs completed in 0.205 hours.\n",
            "Optimizer stripped from runs/detect/yolov8_custom4/weights/last.pt, 5.5MB\n",
            "Optimizer stripped from runs/detect/yolov8_custom4/weights/best.pt, 5.5MB\n",
            "\n",
            "Validating runs/detect/yolov8_custom4/weights/best.pt...\n",
            "Ultralytics 8.3.92 ğŸš€ Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "YOLO11n summary (fused): 100 layers, 2,583,127 parameters, 0 gradients, 6.3 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:04<00:00,  1.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        167        167      0.796      0.799      0.843      0.675\n",
            "                  five         77         77      0.817       0.81      0.868      0.662\n",
            "                  four         21         21      0.838      0.857      0.851      0.676\n",
            "                   one         19         19      0.736      0.789      0.839      0.678\n",
            "                 three         27         27      0.782        0.8      0.827      0.708\n",
            "                   two         23         23      0.806      0.739      0.831      0.652\n",
            "Speed: 0.3ms preprocess, 3.7ms inference, 0.0ms loss, 5.2ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/yolov8_custom4\u001b[0m\n",
            "Ultralytics 8.3.92 ğŸš€ Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "YOLO11n summary (fused): 100 layers, 2,583,127 parameters, 0 gradients, 6.3 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/Hand-Gesture-Recognition-6/valid/labels.cache... 167 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 167/167 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:02<00:00,  4.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        167        167      0.795      0.799      0.844      0.676\n",
            "                  five         77         77      0.816      0.809      0.868      0.664\n",
            "                  four         21         21      0.838      0.857      0.851      0.676\n",
            "                   one         19         19      0.737      0.789      0.839      0.678\n",
            "                 three         27         27      0.782      0.799      0.827      0.708\n",
            "                   two         23         23      0.804      0.739      0.833      0.653\n",
            "Speed: 3.6ms preprocess, 4.9ms inference, 0.0ms loss, 1.7ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/yolov8_custom42\u001b[0m\n",
            "0.6757454864010204\n"
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "from IPython.display import display, Image\n",
        "# Load a pre-trained YOLOv8 model\n",
        "model = YOLO(\"/content/yolo11n.pt\")\n",
        "\n",
        "# Train the model\n",
        "results = model.train(\n",
        "    data=\"/content/Hand-Gesture-Recognition-6/data.yaml\",\n",
        "    epochs=60,\n",
        "    batch=16,                # Batch size\n",
        "    imgsz=640,               # Image size\n",
        "    device=\"0\",\n",
        "    name=\"yolov8_custom\"     # Name of the training run\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "metrics = model.val()\n",
        "print(metrics.box.map)  # Print mAP score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding"
      ],
      "metadata": {
        "id": "Vu5sNVII92P_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/runs/detect/yolov8_custom4/weights/best.pt /content/drive/MyDrive/hand_recog/yolo11_hand_recg_n.pt"
      ],
      "metadata": {
        "id": "N8O3Ks5J9VBU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo val model=/content/runs/detect/yolov8_custom2/weights/best.pt data=/content/Hand-Gesture-Recognition-6/data.yaml split=val"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqgJ83sA9-H2",
        "outputId": "051256d2-1f5b-48b1-c6c4-a30e42bc067e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.92 ğŸš€ Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 92 layers, 25,842,655 parameters, 0 gradients, 78.7 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/Hand-Gesture-Recognition-6/valid/labels.cache... 167 images, 0 backgrounds, 0 corrupt: 100% 167/167 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 11/11 [00:05<00:00,  1.90it/s]\n",
            "                   all        167        167      0.781      0.843      0.897      0.731\n",
            "                  five         77         77      0.748      0.922      0.888       0.69\n",
            "                  four         21         21      0.613      0.905      0.933      0.755\n",
            "                   one         19         19      0.786      0.775      0.852      0.727\n",
            "                 three         27         27      0.808      0.777      0.859      0.753\n",
            "                   two         23         23      0.951      0.836      0.953      0.729\n",
            "Speed: 3.8ms preprocess, 21.3ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val6\u001b[0m\n",
            "ğŸ’¡ Learn more at https://docs.ultralytics.com/modes/val\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo val model=/content/runs/detect/yolov8_custom2/weights/best.pt data=/content/Hand-Gesture-Recognition-6/data.yaml split=test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zToBcJg5Wu8i",
        "outputId": "fee06f3c-d109-432c-d2d0-3a4fc9c2b060"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.92 ğŸš€ Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 92 layers, 25,842,655 parameters, 0 gradients, 78.7 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/Hand-Gesture-Recognition-6/test/labels.cache... 85 images, 0 backgrounds, 0 corrupt: 100% 85/85 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 6/6 [00:03<00:00,  1.69it/s]\n",
            "                   all         85         86      0.929      0.725      0.856      0.685\n",
            "                  five         45         46      0.886      0.849      0.892      0.696\n",
            "                  four         11         11      0.834      0.727      0.799      0.639\n",
            "                   one          7          7          1      0.599      0.832      0.628\n",
            "                 three          8          8      0.925      0.625      0.799      0.679\n",
            "                   two         14         14          1      0.826      0.958      0.782\n",
            "Speed: 0.3ms preprocess, 28.6ms inference, 0.0ms loss, 4.1ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val5\u001b[0m\n",
            "ğŸ’¡ Learn more at https://docs.ultralytics.com/modes/val\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo task=detect mode=predict model=/content/runs/detect/yolov8_custom/weights/best.pt conf=0.25 source=/content/Hand-Gesture-Recognition-6/test/images/IMG-20230312-WA0758_jpg.rf.a2268b578eb9d8a617cd6a5691bbdb21.jpg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPciUJ6F-2mt",
        "outputId": "47da7eca-41b6-4033-a57a-de4d2e50bff9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.92 ğŸš€ Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 92 layers, 25,842,655 parameters, 0 gradients, 78.7 GFLOPs\n",
            "\n",
            "image 1/1 /content/Hand-Gesture-Recognition-6/test/images/IMG-20230312-WA0758_jpg.rf.a2268b578eb9d8a617cd6a5691bbdb21.jpg: 640x640 1 two, 37.0ms\n",
            "Speed: 4.2ms preprocess, 37.0ms inference, 159.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict2\u001b[0m\n",
            "ğŸ’¡ Learn more at https://docs.ultralytics.com/modes/predict\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Image(filename=f'/content/runs/detect/predict2/IMG-20230312-WA0758_jpg.rf.a2268b578eb9d8a617cd6a5691bbdb21.jpg', width=600)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "PUKhGiEbA9sd",
        "outputId": "dc95bafb-c4ff-4cf9-dd1c-3d2526c76663"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/jpeg": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "image/jpeg": {
              "width": 600
            }
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo export model=/content/runs/detect/yolov8_custom/weights/best.pt format=openvino"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzZm2R4iIivF",
        "outputId": "1390fdc7-57f4-4ae8-ffaa-1866eed2b2bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.91 ğŸš€ Python-3.11.11 torch-2.6.0+cu124 CPU (Intel Xeon 2.00GHz)\n",
            "Model summary (fused): 72 layers, 11,127,519 parameters, 0 gradients, 28.4 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/content/runs/detect/yolov8_custom/weights/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 9, 8400) (21.5 MB)\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['openvino>=2024.0.0,!=2025.0.0'] not found, attempting AutoUpdate...\n",
            "Collecting openvino!=2025.0.0,>=2024.0.0\n",
            "  Downloading openvino-2024.6.0-17404-cp311-cp311-manylinux2014_x86_64.whl.metadata (8.3 kB)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.16.6 in /usr/local/lib/python3.11/dist-packages (from openvino!=2025.0.0,>=2024.0.0) (2.0.2)\n",
            "Collecting openvino-telemetry>=2023.2.1 (from openvino!=2025.0.0,>=2024.0.0)\n",
            "  Downloading openvino_telemetry-2025.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from openvino!=2025.0.0,>=2024.0.0) (24.2)\n",
            "Downloading openvino-2024.6.0-17404-cp311-cp311-manylinux2014_x86_64.whl (44.7 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 44.7/44.7 MB 61.2 MB/s eta 0:00:00\n",
            "Downloading openvino_telemetry-2025.1.0-py3-none-any.whl (25 kB)\n",
            "Installing collected packages: openvino-telemetry, openvino\n",
            "Successfully installed openvino-2024.6.0 openvino-telemetry-2025.1.0\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success âœ… 6.5s, installed 1 package: ['openvino>=2024.0.0,!=2025.0.0']\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m âš ï¸ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mOpenVINO:\u001b[0m starting export with openvino 2024.6.0-17404-4c0f47d2335-releases/2024/6...\n",
            "\u001b[34m\u001b[1mOpenVINO:\u001b[0m export success âœ… 10.8s, saved as '/content/runs/detect/yolov8_custom/weights/best_openvino_model/' (42.8 MB)\n",
            "\n",
            "Export complete (13.1s)\n",
            "Results saved to \u001b[1m/content/runs/detect/yolov8_custom/weights\u001b[0m\n",
            "Predict:         yolo predict task=detect model=/content/runs/detect/yolov8_custom/weights/best_openvino_model imgsz=640  \n",
            "Validate:        yolo val task=detect model=/content/runs/detect/yolov8_custom/weights/best_openvino_model imgsz=640 data=/content/Hand-Gesture-Recognition-6/data.yaml  \n",
            "Visualize:       https://netron.app\n",
            "ğŸ’¡ Learn more at https://docs.ultralytics.com/modes/export\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/runs/detect/yolov8_custom/weights/best_openvino_model/* /content/drive/MyDrive/hand_recog/"
      ],
      "metadata": {
        "id": "KoH-gB-uI721"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2b_HGLLpJGV-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}